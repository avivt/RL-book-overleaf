@article{KearnsS02,
  author    = {Michael J. Kearns and
               Satinder P. Singh},
  title     = {Near-Optimal Reinforcement Learning in Polynomial Time},
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  pages     = {209--232},
  year      = {2002},
  url       = {https://doi.org/10.1023/A:1017984413808},
  doi       = {10.1023/A:1017984413808},
  timestamp = {Sun, 28 May 2017 13:18:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ml/KearnsS02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{KearnsS98a,
  author    = {Michael J. Kearns and
               Satinder P. Singh},
  title     = {Finite-Sample Convergence Rates for Q-Learning and Indirect Algorithms},
  booktitle = {Advances in Neural Information Processing Systems 11, {[NIPS} Conference,
               Denver, Colorado, USA, November 30 - December 5, 1998]},
  pages     = {996--1002},
  year      = {1998}
}

@article{BrafmanT02,
  author    = {Ronen I. Brafman and
               Moshe Tennenholtz},
  title     = {{R-MAX} - {A} General Polynomial Time Algorithm for Near-Optimal Reinforcement
               Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {3},
  pages     = {213--231},
  year      = {2002},
  url       = {http://www.jmlr.org/papers/v3/brafman02a.html},
  timestamp = {Thu, 05 Feb 2004 13:43:02 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/jmlr/BrafmanT02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{StrehlLL09,
  author    = {Alexander L. Strehl and
               Lihong Li and
               Michael L. Littman},
  title     = {Reinforcement Learning in Finite MDPs: {PAC} Analysis},
  journal   = {Journal of Machine Learning Research},
  volume    = {10},
  pages     = {2413--2444},
  year      = {2009},
  url       = {http://doi.acm.org/10.1145/1577069.1755867},
  doi       = {10.1145/1577069.1755867},
  timestamp = {Mon, 13 Nov 2017 02:31:07 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/jmlr/StrehlLL09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Inbook{Li2012,
author="Li, Lihong",
editor="Wiering, Marco
and van Otterlo, Martijn",
title="Sample Complexity Bounds of Exploration",
bookTitle="Reinforcement Learning: State-of-the-Art",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="175--204",
abstract="Efficient exploration is widely recognized as a fundamental challenge inherent in reinforcement learning. Algorithms that explore efficiently converge faster to near-optimal policies. While heuristics techniques are popular in practice, they lack formal guarantees and may not work well in general. This chapter studies algorithms with polynomial sample complexity of exploration, both model-based and model-free ones, in a unified manner. These so-called PAC-MDP algorithms behave near-optimally except in a ``small'' number of steps with high probability. A new learning model known as KWIK is used to unify most existing model-based PAC-MDP algorithms for various subclasses of Markov decision processes.We also compare the sample-complexity framework to alternatives for formalizing exploration efficiency such as regret minimization and Bayes optimal solutions.",
isbn="978-3-642-27645-3",
doi="10.1007/978-3-642-27645-3_6",
url="https://doi.org/10.1007/978-3-642-27645-3_6"
}


@article{SinghS96,
  author    = {Satinder P. Singh and
               Richard S. Sutton},
  title     = {Reinforcement Learning with Replacing Eligibility Traces},
  journal   = {Machine Learning},
  volume    = {22},
  number    = {1-3},
  pages     = {123--158},
  year      = {1996},
  url       = {https://doi.org/10.1023/A:1018012322525},
  doi       = {10.1023/A:1018012322525},
  timestamp = {Sun, 28 May 2017 13:18:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ml/SinghS96},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Even-DarM03,
  author    = {Eyal Even{-}Dar and
               Yishay Mansour},
  title     = {Learning Rates for Q-learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {5},
  pages     = {1--25},
  year      = {2003},
  url       = {http://www.jmlr.org/papers/v5/evendar03a.html},
  timestamp = {Thu, 05 Feb 2004 13:53:36 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/jmlr/Even-DarM03},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{SeijenHWW09,
  author    = {Harm van Seijen and
               Hado van Hasselt and
               Shimon Whiteson and
               Marco A. Wiering},
  title     = {A theoretical and empirical analysis of Expected Sarsa},
  booktitle = {{IEEE} Symposium on Adaptive Dynamic Programming and Reinforcement
               Learning, {ADPRL} 2009, Nashville, TN, USA, March 31 - April 1, 2009},
  pages     = {177--184},
  year      = {2009}
}

@book{SuttonB98,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement learning - an introduction},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  year      = {1998},
  url       = {http://www.worldcat.org/oclc/37293240},
  isbn      = {0262193981},
  timestamp = {Wed, 26 Apr 2017 17:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/books/lib/SuttonB98},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Tesauro95,
  author    = {Gerald Tesauro},
  title     = {Temporal Difference Learning and TD-Gammon},
  journal   = {Commun. {ACM}},
  volume    = {38},
  number    = {3},
  pages     = {58--68},
  year      = {1995},
  url       = {http://doi.acm.org/10.1145/203330.203343},
  doi       = {10.1145/203330.203343},
  timestamp = {Tue, 07 Jun 2011 16:52:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/cacm/Tesauro95},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Tesauro02,
  author    = {Gerald Tesauro},
  title     = {Programming backgammon using self-teaching neural nets},
  journal   = {Artif. Intell.},
  volume    = {134},
  number    = {1-2},
  pages     = {181--199},
  year      = {2002},
  url       = {https://doi.org/10.1016/S0004-3702(01)00110-2},
  doi       = {10.1016/S0004-3702(01)00110-2},
  timestamp = {Sat, 27 May 2017 14:24:43 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ai/Tesauro02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{MnihKSRVBGRFOPB15,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Andrei A. Rusu and
               Joel Veness and
               Marc G. Bellemare and
               Alex Graves and
               Martin A. Riedmiller and
               Andreas Fidjeland and
               Georg Ostrovski and
               Stig Petersen and
               Charles Beattie and
               Amir Sadik and
               Ioannis Antonoglou and
               Helen King and
               Dharshan Kumaran and
               Daan Wierstra and
               Shane Legg and
               Demis Hassabis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  url       = {https://doi.org/10.1038/nature14236},
  doi       = {10.1038/nature14236},
  timestamp = {Sat, 20 May 2017 00:24:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/nature/MnihKSRVBGRFOPB15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{KohlS04,
  author    = {Nate Kohl and
               Peter Stone},
  title     = {Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion},
  booktitle = {Proceedings of the 2004 {IEEE} International Conference on Robotics
               and Automation, {ICRA} 2004, April 26 - May 1, 2004, New Orleans,
               LA, {USA}},
  pages     = {2619--2624},
  year      = {2004}
}

@article{SilverHMGSDSAPL16,
  author    = {David Silver and
               Aja Huang and
               Chris J. Maddison and
               Arthur Guez and
               Laurent Sifre and
               George van den Driessche and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Vedavyas Panneershelvam and
               Marc Lanctot and
               Sander Dieleman and
               Dominik Grewe and
               John Nham and
               Nal Kalchbrenner and
               Ilya Sutskever and
               Timothy P. Lillicrap and
               Madeleine Leach and
               Koray Kavukcuoglu and
               Thore Graepel and
               Demis Hassabis},
  title     = {Mastering the game of Go with deep neural networks and tree search},
  journal   = {Nature},
  volume    = {529},
  number    = {7587},
  pages     = {484--489},
  year      = {2016},
  url       = {https://doi.org/10.1038/nature16961},
  doi       = {10.1038/nature16961},
  timestamp = {Sat, 20 May 2017 00:24:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/nature/SilverHMGSDSAPL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{AbbeelCN2010,
 author = {Abbeel, Pieter and Coates, Adam and Ng, Andrew Y.},
 title = {Autonomous Helicopter Aerobatics Through Apprenticeship Learning},
 journal = {Int. J. Rob. Res.},
 issue_date = {November  2010},
 volume = {29},
 number = {13},
 month = nov,
 year = {2010},
 issn = {0278-3649},
 pages = {1608--1639},
 numpages = {32},
 url = {http://dx.doi.org/10.1177/0278364910371999},
 doi = {10.1177/0278364910371999},
 acmid = {1894944},
 publisher = {Sage Publications, Inc.},
 address = {Thousand Oaks, CA, USA},
 keywords = {Apprenticeship learning, autonomous flight, autonomous helicopter, helicopter aerobatics, learning from demonstrations},
}

@inproceedings{KearnsMN99,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = {Approximate Planning in Large POMDPs via Reusable Trajectories},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference,
               Denver, Colorado, USA, November 29 - December 4, 1999]},
  pages     = {1001--1007},
  year      = {1999},
  crossref  = {DBLP:conf/nips/1999},
  url       = {http://papers.nips.cc/paper/1664-approximate-planning-in-large-pomdps-via-reusable-trajectories},
  timestamp = {Thu, 11 Dec 2014 17:34:08 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/nips/KearnsMN99},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{KearnsMN02,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = {A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov
               Decision Processes},
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  pages     = {193--208},
  year      = {2002},
  url       = {https://doi.org/10.1023/A:1017932429737},
  doi       = {10.1023/A:1017932429737},
  timestamp = {Sun, 28 May 2017 13:18:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ml/KearnsMN02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{PieterN04,
  author    = {Pieter Abbeel and
               Andrew Y. Ng},
  title     = {Apprenticeship learning via inverse reinforcement learning},
  booktitle = {Machine Learning, Proceedings of the Twenty-first International Conference
               {(ICML} 2004), Banff, Alberta, Canada, July 4-8, 2004},
  year      = {2004}
}

@inproceedings{NgR00,
  author    = {Andrew Y. Ng and
               Stuart J. Russell},
  title     = {Algorithms for Inverse Reinforcement Learning},
  booktitle = {Proceedings of the Seventeenth International Conference on Machine
               Learning {(ICML} 2000), Stanford University, Stanford, CA, USA, June
               29 - July 2, 2000},
  pages     = {663--670},
  year      = {2000}
}

@article{TsitsiklisVR97,
 author = {J. Tsitsiklis and B. Van Roy},
 title = {An Analysis of Temporal-Difference Learning with Function Approximation},
 journal = {IEEE Trans. on Automatic Control},
 volume = {42},
 number = {5},
 year = {1997},
 pages = {674--690},
}

@book{BookCormenLRS2009,
  author    = {Thomas H. Cormen and
               Charles E. Leiserson and
               Ronald L. Rivest and
               Clifford Stein},
  title     = {Introduction to Algorithms, 3rd Edition},
  publisher = {{MIT} Press},
  year      = {2009},
  url       = {http://mitpress.mit.edu/books/introduction-algorithms}
}

@inproceedings{DannB15,
  author    = {Christoph Dann and
               Emma Brunskill},
  editor    = {Corinna Cortes and
               Neil D. Lawrence and
               Daniel D. Lee and
               Masashi Sugiyama and
               Roman Garnett},
  title     = {Sample Complexity of Episodic Fixed-Horizon Reinforcement Learning},
  booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
               on Neural Information Processing Systems 2015, December 7-12, 2015,
               Montreal, Quebec, Canada},
  pages     = {2818--2826},
  year      = {2015}
}
