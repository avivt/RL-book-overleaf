@article{KearnsS02,
  author    = {Michael J. Kearns and
               Satinder P. Singh},
  title     = {Near-Optimal Reinforcement Learning in Polynomial Time},
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  pages     = {209--232},
  year      = {2002},
  url       = {https://doi.org/10.1023/A:1017984413808},
  doi       = {10.1023/A:1017984413808},
  timestamp = {Sun, 28 May 2017 13:18:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ml/KearnsS02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{munos2007performance,
  title={Performance bounds in l\_p-norm for approximate value iteration},
  author={Munos, R{\'e}mi},
  journal={SIAM journal on control and optimization},
  volume={46},
  number={2},
  pages={541--561},
  year={2007},
  publisher={SIAM}
}

@inproceedings{kearns2000bias,
  title={Bias-Variance Error Bounds for Temporal Difference Updates.},
  author={Kearns, Michael J and Singh, Satinder},
  booktitle={COLT},
  pages={142--147},
  year={2000}
}

@inproceedings{KearnsS98a,
  author    = {Michael J. Kearns and
               Satinder P. Singh},
  title     = {Finite-Sample Convergence Rates for Q-Learning and Indirect Algorithms},
  booktitle = {Advances in Neural Information Processing Systems 11, {[NIPS} Conference,
               Denver, Colorado, USA, November 30 - December 5, 1998]},
  pages     = {996--1002},
  year      = {1998}
}

@article{BrafmanT02,
  author    = {Ronen I. Brafman and
               Moshe Tennenholtz},
  title     = {{R-MAX} - {A} General Polynomial Time Algorithm for Near-Optimal Reinforcement
               Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {3},
  pages     = {213--231},
  year      = {2002},
  url       = {http://www.jmlr.org/papers/v3/brafman02a.html},
  timestamp = {Thu, 05 Feb 2004 13:43:02 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/jmlr/BrafmanT02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{StrehlLL09,
  author    = {Alexander L. Strehl and
               Lihong Li and
               Michael L. Littman},
  title     = {Reinforcement Learning in Finite MDPs: {PAC} Analysis},
  journal   = {Journal of Machine Learning Research},
  volume    = {10},
  pages     = {2413--2444},
  year      = {2009},
  url       = {http://doi.acm.org/10.1145/1577069.1755867},
  doi       = {10.1145/1577069.1755867},
  timestamp = {Mon, 13 Nov 2017 02:31:07 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/jmlr/StrehlLL09},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Inbook{Li2012,
author="Li, Lihong",
title="Sample Complexity Bounds of Exploration",
bookTitle="Reinforcement Learning: State-of-the-Art",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="175--204",
abstract="Efficient exploration is widely recognized as a fundamental challenge inherent in reinforcement learning. Algorithms that explore efficiently converge faster to near-optimal policies. While heuristics techniques are popular in practice, they lack formal guarantees and may not work well in general. This chapter studies algorithms with polynomial sample complexity of exploration, both model-based and model-free ones, in a unified manner. These so-called PAC-MDP algorithms behave near-optimally except in a ``small'' number of steps with high probability. A new learning model known as KWIK is used to unify most existing model-based PAC-MDP algorithms for various subclasses of Markov decision processes.We also compare the sample-complexity framework to alternatives for formalizing exploration efficiency such as regret minimization and Bayes optimal solutions.",
isbn="978-3-642-27645-3",
doi="10.1007/978-3-642-27645-3_6",
url="https://doi.org/10.1007/978-3-642-27645-3_6"
}


@article{SinghS96,
  author    = {Satinder P. Singh and
               Richard S. Sutton},
  title     = {Reinforcement Learning with Replacing Eligibility Traces},
  journal   = {Machine Learning},
  volume    = {22},
  number    = {1-3},
  pages     = {123--158},
  year      = {1996},
  url       = {https://doi.org/10.1023/A:1018012322525},
  doi       = {10.1023/A:1018012322525},
  timestamp = {Sun, 28 May 2017 13:18:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ml/SinghS96},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Even-DarM03,
  author    = {Eyal Even{-}Dar and
               Yishay Mansour},
  title     = {Learning Rates for Q-learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {5},
  pages     = {1--25},
  year      = {2003},
  url       = {http://www.jmlr.org/papers/v5/evendar03a.html},
  timestamp = {Thu, 05 Feb 2004 13:53:36 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/jmlr/Even-DarM03},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{SeijenHWW09,
  author    = {Harm van Seijen and
               Hado van Hasselt and
               Shimon Whiteson and
               Marco A. Wiering},
  title     = {A theoretical and empirical analysis of Expected Sarsa},
  booktitle = {{IEEE} Symposium on Adaptive Dynamic Programming and Reinforcement
               Learning, {ADPRL} 2009, Nashville, TN, USA, March 31 - April 1, 2009},
  pages     = {177--184},
  year      = {2009}
}

@book{SuttonB98,
  author    = {Richard S. Sutton and
               Andrew G. Barto},
  title     = {Reinforcement learning - an introduction},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  year      = {1998},
  url       = {http://www.worldcat.org/oclc/37293240},
  isbn      = {0262193981},
  timestamp = {Wed, 26 Apr 2017 17:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/books/lib/SuttonB98},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Tesauro95,
  author    = {Gerald Tesauro},
  title     = {Temporal Difference Learning and TD-Gammon},
  journal   = {Commun. {ACM}},
  volume    = {38},
  number    = {3},
  pages     = {58--68},
  year      = {1995},
  url       = {http://doi.acm.org/10.1145/203330.203343},
  doi       = {10.1145/203330.203343},
  timestamp = {Tue, 07 Jun 2011 16:52:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/cacm/Tesauro95},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Tesauro02,
  author    = {Gerald Tesauro},
  title     = {Programming backgammon using self-teaching neural nets},
  journal   = {Artif. Intell.},
  volume    = {134},
  number    = {1-2},
  pages     = {181--199},
  year      = {2002},
  url       = {https://doi.org/10.1016/S0004-3702(01)00110-2},
  doi       = {10.1016/S0004-3702(01)00110-2},
  timestamp = {Sat, 27 May 2017 14:24:43 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ai/Tesauro02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{MnihKSRVBGRFOPB15,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Andrei A. Rusu and
               Joel Veness and
               Marc G. Bellemare and
               Alex Graves and
               Martin A. Riedmiller and
               Andreas Fidjeland and
               Georg Ostrovski and
               Stig Petersen and
               Charles Beattie and
               Amir Sadik and
               Ioannis Antonoglou and
               Helen King and
               Dharshan Kumaran and
               Daan Wierstra and
               Shane Legg and
               Demis Hassabis},
  title     = {Human-level control through deep reinforcement learning},
  journal   = {Nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  url       = {https://doi.org/10.1038/nature14236},
  doi       = {10.1038/nature14236},
  timestamp = {Sat, 20 May 2017 00:24:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/nature/MnihKSRVBGRFOPB15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{KohlS04,
  author    = {Nate Kohl and
               Peter Stone},
  title     = {Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion},
  booktitle = {Proceedings of the 2004 {IEEE} International Conference on Robotics
               and Automation, {ICRA} 2004, April 26 - May 1, 2004, New Orleans,
               LA, {USA}},
  pages     = {2619--2624},
  year      = {2004}
}

@article{SilverHMGSDSAPL16,
  author    = {David Silver and
               Aja Huang and
               Chris J. Maddison and
               Arthur Guez and
               Laurent Sifre and
               George van den Driessche and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Vedavyas Panneershelvam and
               Marc Lanctot and
               Sander Dieleman and
               Dominik Grewe and
               John Nham and
               Nal Kalchbrenner and
               Ilya Sutskever and
               Timothy P. Lillicrap and
               Madeleine Leach and
               Koray Kavukcuoglu and
               Thore Graepel and
               Demis Hassabis},
  title     = {Mastering the game of Go with deep neural networks and tree search},
  journal   = {Nature},
  volume    = {529},
  number    = {7587},
  pages     = {484--489},
  year      = {2016},
  url       = {https://doi.org/10.1038/nature16961},
  doi       = {10.1038/nature16961},
  timestamp = {Sat, 20 May 2017 00:24:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/nature/SilverHMGSDSAPL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{AbbeelCN2010,
 author = {Abbeel, Pieter and Coates, Adam and Ng, Andrew Y.},
 title = {Autonomous Helicopter Aerobatics Through Apprenticeship Learning},
 journal = {Int. J. Rob. Res.},
 issue_date = {November  2010},
 volume = {29},
 number = {13},
 month = nov,
 year = {2010},
 issn = {0278-3649},
 pages = {1608--1639},
 numpages = {32},
 url = {http://dx.doi.org/10.1177/0278364910371999},
 doi = {10.1177/0278364910371999},
 acmid = {1894944},
 publisher = {Sage Publications, Inc.},
 address = {Thousand Oaks, CA, USA},
 keywords = {Apprenticeship learning, autonomous flight, autonomous helicopter, helicopter aerobatics, learning from demonstrations},
}

@inproceedings{KearnsMN99,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = {Approximate Planning in Large POMDPs via Reusable Trajectories},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference,
               Denver, Colorado, USA, November 29 - December 4, 1999]},
  pages     = {1001--1007},
  year      = {1999},
  crossref  = {DBLP:conf/nips/1999},
  url       = {http://papers.nips.cc/paper/1664-approximate-planning-in-large-pomdps-via-reusable-trajectories},
  timestamp = {Thu, 11 Dec 2014 17:34:08 +0100},
  biburl    = {https://dblp.org/rec/bib/conf/nips/KearnsMN99},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{KearnsMN02,
  author    = {Michael J. Kearns and
               Yishay Mansour and
               Andrew Y. Ng},
  title     = {A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov
               Decision Processes},
  journal   = {Machine Learning},
  volume    = {49},
  number    = {2-3},
  pages     = {193--208},
  year      = {2002},
  url       = {https://doi.org/10.1023/A:1017932429737},
  doi       = {10.1023/A:1017932429737},
  timestamp = {Sun, 28 May 2017 13:18:23 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/ml/KearnsMN02},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{PieterN04,
  author    = {Pieter Abbeel and
               Andrew Y. Ng},
  title     = {Apprenticeship learning via inverse reinforcement learning},
  booktitle = {Machine Learning, Proceedings of the Twenty-first International Conference
               {(ICML} 2004), Banff, Alberta, Canada, July 4-8, 2004},
  year      = {2004}
}

@inproceedings{NgR00,
  author    = {Andrew Y. Ng and
               Stuart J. Russell},
  title     = {Algorithms for Inverse Reinforcement Learning},
  booktitle = {Proceedings of the Seventeenth International Conference on Machine
               Learning {(ICML} 2000), Stanford University, Stanford, CA, USA, June
               29 - July 2, 2000},
  pages     = {663--670},
  year      = {2000}
}

@article{TsitsiklisVR97,
 author = {J. Tsitsiklis and B. Van Roy},
 title = {An Analysis of Temporal-Difference Learning with Function Approximation},
 journal = {IEEE Trans. on Automatic Control},
 volume = {42},
 number = {5},
 year = {1997},
 pages = {674--690},
}

@book{BookCormenLRS2009,
  author    = {Thomas H. Cormen and
               Charles E. Leiserson and
               Ronald L. Rivest and
               Clifford Stein},
  title     = {Introduction to Algorithms, 3rd Edition},
  publisher = {{MIT} Press},
  year      = {2009},
  url       = {http://mitpress.mit.edu/books/introduction-algorithms}
}

@inproceedings{DannB15,
  author    = {Christoph Dann and
               Emma Brunskill},
  editor    = {Corinna Cortes and
               Neil D. Lawrence and
               Daniel D. Lee and
               Masashi Sugiyama and
               Roman Garnett},
  title     = {Sample Complexity of Episodic Fixed-Horizon Reinforcement Learning},
  booktitle = {Advances in Neural Information Processing Systems 28: Annual Conference
               on Neural Information Processing Systems 2015, December 7-12, 2015,
               Montreal, Quebec, Canada},
  pages     = {2818--2826},
  year      = {2015}
}


@article{kearns2002sparse,
  title={A sparse sampling algorithm for near-optimal planning in large Markov decision processes},
  author={Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
  journal={Machine learning},
  volume={49},
  number={2-3},
  pages={193--208},
  year={2002},
  publisher={Springer}
}

@inproceedings{kocsis2006bandit,
  title={Bandit based monte-carlo planning},
  author={Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle={European conference on machine learning},
  pages={282--293},
  year={2006},
  organization={Springer}
}

@incollection{gordon1995stable,
  title={Stable function approximation in dynamic programming},
  author={Gordon, Geoffrey J},
  booktitle={Machine Learning Proceedings 1995},
  pages={261--268},
  year={1995},
  publisher={Elsevier}
}

@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{Samuel62,
  author    = {Arthur L. Samuel},
  title     = {Artificial intelligence - a frontier of automation},
  journal   = {Elektron. Rechenanlagen},
  volume    = {4},
  number    = {4},
  pages     = {173--177},
  year      = {1962},
  url       = {https://doi.org/10.1524/itit.1962.4.16.173},
  doi       = {10.1524/itit.1962.4.16.173},
  timestamp = {Mon, 18 May 2020 12:40:49 +0200},
  biburl    = {https://dblp.org/rec/journals/it/Samuel62.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{DeepBlue,
title = {Deep Blue},
journal = {Artificial Intelligence},
volume = {134},
number = {1},
pages = {57-83},
year = {2002},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(01)00129-1},
url = {https://www.sciencedirect.com/science/article/pii/S0004370201001291},
author = {Murray Campbell and A.Joseph Hoane and Feng-hsiung Hsu},
keywords = {Computer chess, Game tree search, Parallel search, Selective search, Search extensions, Evaluation function},
abstract = {Deep Blue is the chess machine that defeated then-reigning World Chess Champion Garry Kasparov in a six-game match in 1997. There were a number of factors that contributed to this success, including: •a single-chip chess search engine,•a massively parallel system with multiple levels of parallelism,•a strong emphasis on search extensions,•a complex evaluation function, and•effective use of a Grandmaster game database. This paper describes the Deep Blue system, and gives some of the rationale that went into the design decisions behind Deep Blue.}
}

@article{Karp78,
  author    = {Richard M. Karp},
  title     = {A characterization of the minimum cycle mean in a digraph},
  journal   = {Discret. Math.},
  volume    = {23},
  number    = {3},
  pages     = {309--311},
  year      = {1978},
  url       = {https://doi.org/10.1016/0012-365X(78)90011-0},
  doi       = {10.1016/0012-365X(78)90011-0},
  timestamp = {Fri, 12 Feb 2021 13:44:46 +0100},
  biburl    = {https://dblp.org/rec/journals/dm/Karp78.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ChaturvediM17,
  author    = {Mmanu Chaturvedi and
               Ross M. McConnell},
  title     = {A note on finding minimum mean cycle},
  journal   = {Inf. Process. Lett.},
  volume    = {127},
  pages     = {21--22},
  year      = {2017},
  url       = {https://doi.org/10.1016/j.ipl.2017.06.007},
  doi       = {10.1016/j.ipl.2017.06.007},
  timestamp = {Tue, 12 Sep 2017 17:58:15 +0200},
  biburl    = {https://dblp.org/rec/journals/ipl/ChaturvediM17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{cormen2009introduction,
  title={Introduction to algorithms},
  author={Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and Stein, Clifford},
  year={2009},
  publisher={MIT press}
}

@book{KleinbergTardos06,
  author = {Kleinberg, Jon and Tardos, \'Eva},
  publisher = {Addison Wesley},
  title = {Algorithm Design},
  year = 2006
}
@book{DasguptaPapadimitriouVazirani08,
  author    = {Sanjoy Dasgupta and
               Christos H. Papadimitriou and
               Umesh V. Vazirani},
  title     = {Algorithms},
  publisher = {McGraw-Hill},
  year      = {2008}
}

@book{van1996weak,
  title={Weak Convergence and Empirical Processes: With Applications to Statistics},
  author={van der Vaart, AW and van der Vaart, A.W. and van der Vaart, A. and Wellner, J.},
  isbn={9780387946405},
  lccn={95049099},
  series={Springer Series in Statistics},
  url={https://books.google.fr/books?id=seH8dMrEgggC},
  year={1996},
  publisher={Springer}
}


@book{Howard1960,
  author = {Howard, R. A.},
  publisher = {MIT Press},
  title = {Dynamic Programming and Markov Processes},
  year = 1960
}

@book{Bellman:DynamicProgramming,
  author = {Bellman, Richard},
  publisher = {Dover Publications},
  title = {{Dynamic Programming}},
  year = 1957
}


@article{Shapley53,
  author    = {L. S. Shapley},
  title     = {Stochastic games},
  journal   = {Proc Natl Acad Sci USA},
  volume    = {39},
  pages     = {1095–-1100},
  year      = {1953}
}

@book{puterman2014markov,
  author = {Puterman, Martin L},
  publisher = {John Wiley \& Sons},
  title = {Markov decision processes: discrete stochastic dynamic programming},
  year = 2014
}

@book{BertsekasTsitsiklis96,
  author = {Bertsekas, D. P. and Tsitsiklis, J. N.},
  booktitle = {Neuro-dynamic programming.},
  publisher = {Athena Scientific},
  title = {Neuro-dynamic programming.},
  year = 1996
}

@book{Bertsekas05,
  author    = {Dimitri P. Bertsekas},
  title     = {Dynamic programming and optimal control, 3rd Edition},
  publisher = {Athena Scientific},
  year      = {2005}
}

@book{Szepesvari,
  author    = {Csaba Szepesv{\'{a}}ri},
  title     = {Algorithms for Reinforcement Learning},
  series    = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  publisher = {Morgan {\&} Claypool Publishers},
  year      = {2010},
}